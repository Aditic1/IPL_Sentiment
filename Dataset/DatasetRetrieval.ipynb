{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4deb2ae6",
   "metadata": {},
   "source": [
    "# Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f850fa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.125.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.29.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.18.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.23.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69f68d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing\n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "print(\"Done importing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656bc82",
   "metadata": {},
   "source": [
    "# YouTube API setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d45b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyBaex6cWvgVO3uabDJVQZeHztAz1NnCz6M\"\n",
    "\n",
    "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fed62f",
   "metadata": {},
   "source": [
    "# Function to retrieve comments from playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36326d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_all_comments_in_playlist(playlist_id):\n",
    "    videos = []\n",
    "\n",
    "    # Fetch all videos in the playlist\n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet\",\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=100  # Adjust as needed\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Iterate over each video in the playlist\n",
    "    for item in response['items']:\n",
    "        video_id = item['snippet']['resourceId']['videoId']\n",
    "        videos.append(video_id)\n",
    "\n",
    "    # Fetch comments and replies for each video\n",
    "    comments = []\n",
    "    for video_id in videos:\n",
    "        video_comments = get_all_comments(video_id)\n",
    "        comments.extend(video_comments)\n",
    "\n",
    "    return comments\n",
    "\n",
    "def get_all_comments(video_id):\n",
    "    comments = []\n",
    "\n",
    "    # Initial request to fetch the first page of comments\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        maxResults=100\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Fetch subsequent pages of comments until all comments have been retrieved\n",
    "    while response:\n",
    "        for item in response['items']:\n",
    "            # Extract top-level comment information\n",
    "            top_level_comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments.append([\n",
    "                top_level_comment['authorDisplayName'],\n",
    "                top_level_comment['textDisplay']\n",
    "            ])\n",
    "            \n",
    "            # Check if there are replies to this comment\n",
    "            if 'replies' in item['snippet']:\n",
    "                # Extract replies\n",
    "                for reply_item in item['snippet']['replies']['comments']:\n",
    "                    reply = reply_item['snippet']\n",
    "                    comments.append([\n",
    "                        reply['authorDisplayName'],\n",
    "                        reply['textDisplay']\n",
    "                    ])\n",
    "\n",
    "        # Check if there are more pages of comments to fetch\n",
    "        if 'nextPageToken' in response:\n",
    "            next_page_token = response['nextPageToken']\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100,\n",
    "                pageToken=next_page_token\n",
    "            )\n",
    "            response = request.execute()\n",
    "        else:\n",
    "            response = None\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Example usage\n",
    "playlist_id = \"PLvy-EhiV7TlqELwdgNqRj0slbT7b847wm\"\n",
    "comments = get_all_comments_in_playlist(playlist_id)\n",
    "df = pd.DataFrame(comments, columns=['author', 'text'])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d461f",
   "metadata": {},
   "source": [
    "# Save DataFrame to a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac52207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('comments.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee386d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  author                                               text\n",
      "0      @SumitGupta-it6ic  bhai lsg ke paas ipl ke is season ka sabse kha...\n",
      "1          @Mrhameedraza             Saare team tere ammi Ki pass pahuchegi\n",
      "2          @Mrhameedraza  Sale Sare team Mein weekness Hai To Tu Hi Chal...\n",
      "3         @ShiaLovERs572                                                 üíúüòà\n",
      "4         @ShiaLovERs572                             KkR üíúüòà Final Winners üíú\n",
      "...                  ...                                                ...\n",
      "9681     @DeepakBehera99  <a href=\"https://youtube.com/@DeepakBehera-er7...\n",
      "9682      @charanteje641                                          4 th view\n",
      "9683        @SMSports276                                                 ‚ù§‚ù§\n",
      "9684   @insidersports232                                               ‚ù§Ô∏è‚ù§Ô∏è\n",
      "9685  @SACHINKUMAR-zk1ch                                           1st view\n",
      "\n",
      "[9686 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('comments.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88597d69",
   "metadata": {},
   "source": [
    "# Convert to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27d6085a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep-translator in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deep-translator) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from deep-translator) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93a7c85f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/10 translated.\n",
      "Batch 2/10 translated.\n",
      "Batch 3/10 translated.\n",
      "Batch 4/10 translated.\n",
      "Batch 5/10 translated.\n",
      "Batch 6/10 translated.\n",
      "Batch 7/10 translated.\n",
      "Batch 8/10 translated.\n"
     ]
    },
    {
     "ename": "NotValidLength",
     "evalue": "There should be a Benaras Pandits (Yogi owner) for UP and MP‚ô•Ô∏èüåπ(even Ayodhya  Bhakts (Owner PM Modi)<br><br>How would a UP MP IPL team called Benaras Pandits and Ayodhya Bhakts describe itself<br>Describing a hypothetical UP MP IPL team called Benaras Pandits and Ayodhya Bhakts requires careful consideration of cultural sensitivities and responsible representation. Here are some ways they could potentially describe themselves, taking into account inclusivity and respect:<br><br>Emphasizing Heritage and Devotion:<br><br>&quot;Rooted in faith, fueled by fervor: Benaras Pandits and Ayodhya Bhakts, where ancient wisdom meets cricketing grit.&quot;<br><br>&quot;Carrying the legacy of the Ganges and the spirit of Ayodhya: Benaras Pandits and Ayodhya Bhakts, playing with devotion, winning with grace.&quot;<br><br>&quot;From the temples of knowledge to the stadiums of glory: Benaras Pandits and Ayodhya Bhakts, batting for unity, bowling for hope.&quot;<br><br>Celebrating Regional Identity:<br><br>&quot;Awadh&#39;s flair, Banaras&#39; chant: Benaras Pandits and Ayodhya Bhakts, where culture meets cricket, passion takes flight.&quot;<br><br>&quot;Taste the saffron sweets, hear the raspy cheers: Benaras Pandits and Ayodhya Bhakts, bringing UP&#39;s spirit to every boundary, every roar.&quot;<br><br>&quot;From Ganga ghats to Chowk&#39;s maze, this team reflects UP&#39;s soul: Benaras Pandits and Ayodhya Bhakts, celebrating diversity, chasing victory as one.&quot;<br><br>Focusing on Sportsmanship and Unity:<br><br>&quot;Beyond faith, beyond borders: Benaras Pandits and Ayodhya Bhakts, united by the love of the game, driven by the spirit of sportsmanship.&quot;<br><br>&quot;Building bridges, not boundaries: Benaras Pandits and Ayodhya Bhakts, where every six unites, every wicket inspires.&quot;<br><br>&quot;More than just a team, a movement: Benaras Pandits and Ayodhya Bhakts, playing for UP&#39;s pride, winning for India&#39;s glory.&quot;<br><br>It&#39;s important to avoid:<br><br>Exclusivity or discriminatory language: The team description should represent the diversity of Uttar Pradesh and be inclusive of all communities.<br><br>Religious or historical references that could be sensitive or controversial: Focus on broader themes of faith, heritage, and regional identity without specific religious or historical allusions.<br><br>Clich√©s or stereotypes: Use vivid language and imagery to evoke the essence of UP and its cultural richness without relying on overused descriptions.<br><br>By emphasizing inclusivity, cultural pride, and the spirit of sportsmanship, the Benaras Pandits and Ayodhya Bhakts can create a compelling team identity that resonates with fans across Uttar Pradesh and beyond.<br><br>Remember, responsible representation and sensitivity are crucial when creating narratives around cultural identities. This approach can ensure the team fosters a sense of unity and celebrates the diverse tapestry of Uttar Pradesh without perpetuating stereotypes or causing offense.<br><br>How are the names a postmodern juxtaposition with other modern team names in IPL<br>The names &quot;Benaras Pandits&quot; and &quot;Ayodhya Bhakts&quot; for a hypothetical UP MP IPL team offer an interesting postmodern juxtaposition with other modern team names in the IPL. Here&#39;s how:<br><br>Postmodern Elements:<br><br>Challenge to Grand Narratives: Both names, particularly &quot;Ayodhya Bhakts,&quot; evoke specific religious and cultural associations. This can be seen as a challenge to the IPL&#39;s broader, global appeal, which seeks to transcend regional and religious affiliations.<br><br>Irony and Self-Awareness: The names employ terms typically associated with traditional identities (&quot;Pandits,&quot; &quot;Bhakts&quot;). This self-awareness, bordering on irony, could be interpreted as a playful subversion of expectations, questioning the rigidity of these identities in a modern sporting context.<br><br>Emphasis on Local Context: Unlike most IPL team names, which tend to be generic or aspirational, these names are deeply rooted in the specific geographic and cultural context of Uttar Pradesh. This local focus highlights the diversity and uniqueness of the region within the larger IPL landscape.<br><br>Juxtaposition with Modern IPL Team Names:<br><br>Majority Focus on City/Franchise: Most IPL team names are built around the city or franchise name, aiming for a neutral and commercially appealing brand. For example, Mumbai Indians, Chennai Super Kings, etc.<br><br>Universal Aspirations: Modern IPL team names often use powerful words or concepts like &quot;Kings,&quot; &quot;Royals,&quot; &quot;Daredevils,&quot; or &quot;Riders,&quot; aiming to convey strength, ambition, and excitement.<br><br>Global Appeal: The IPL strives to be a global sporting event, with team names aiming to resonate with a diverse international audience. This is why most names avoid specific cultural or religious references.<br><br>Potential Reactions:<br><br>Pride and Connection: For fans from Uttar Pradesh, these names could spark a sense of pride and connection to their region&#39;s unique identity. They might resonate with the team&#39;s cultural and religious connotations.<br><br>Discomfort and Disconnection: For fans from other regions or cultural backgrounds, the names might evoke discomfort or a sense of alienation. The religious and historical associations could create barriers to identification with the team.<br><br>Intrigue and Discussion: The unconventional nature of the names might pique interest and lead to discussions about representation, branding, and the IPL&#39;s role in Indian society.<br><br>Ultimately, the effectiveness of these names as a postmodern juxtaposition hinges on their execution and reception. Careful consideration of cultural sensitivities, inclusivity, and the desired brand image is crucial. These names offer a unique opportunity to challenge norms and spark conversations, but they also carry the potential for divisiveness and misunderstanding.<br><br>It&#39;s worth noting that while exploring postmodern elements can be exciting, it&#39;s important to maintain respect and sensitivity towards diverse cultural and religious viewpoints. The goal should be to create a brand identity that is both unique and inclusive, celebrating the spirit of cricket and the tapestry of India&#39;s diverse population.<br><br>I hope this analysis provides a comprehensive understanding of the names&#39; potential impact and the creative possibilities they offer within the context of the IPL. Feel free to explore this further and share your own thoughts and interpretations!<br><br><br><br><br><br><br>Bardüåπüåπ‚ô•Ô∏è‚ô•Ô∏è --> Text length need to be between 0 and 5000 characters",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotValidLength\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m batch_comments \u001b[38;5;241m=\u001b[39m comments_df\u001b[38;5;241m.\u001b[39miloc[start_idx:end_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Translate the batch of comments\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m batch_translations \u001b[38;5;241m=\u001b[39m translate_batch(batch_comments)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Append translations to the list\u001b[39;00m\n\u001b[0;32m     36\u001b[0m translated_texts\u001b[38;5;241m.\u001b[39mextend(batch_translations)\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mtranslate_batch\u001b[1;34m(texts, source_lang, target_lang)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_batch\u001b[39m(texts, source_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m, target_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     translations \u001b[38;5;241m=\u001b[39m GoogleTranslator(source\u001b[38;5;241m=\u001b[39msource_lang, target\u001b[38;5;241m=\u001b[39mtarget_lang)\u001b[38;5;241m.\u001b[39mtranslate_batch(texts)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m translations\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deep_translator\\google.py:122\u001b[0m, in \u001b[0;36mGoogleTranslator.translate_batch\u001b[1;34m(self, batch, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    translate a list of texts\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    @param batch: list of texts you want to translate\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    @return: list of translations\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_translate_batch(batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deep_translator\\base.py:181\u001b[0m, in \u001b[0;36mBaseTranslator._translate_batch\u001b[1;34m(self, batch, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m arr \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch):\n\u001b[1;32m--> 181\u001b[0m     translated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m     arr\u001b[38;5;241m.\u001b[39mappend(translated)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deep_translator\\google.py:57\u001b[0m, in \u001b[0;36mGoogleTranslator.translate\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    function to translate a text\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    @param text: desired text to translate\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    @return: str: translated text\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_input_valid(text, max_chars\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m):\n\u001b[0;32m     58\u001b[0m         text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_same_source_target() \u001b[38;5;129;01mor\u001b[39;00m is_empty(text):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deep_translator\\validate.py:41\u001b[0m, in \u001b[0;36mis_input_valid\u001b[1;34m(text, min_chars, max_chars)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotValidPayload(text)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_chars \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m min_chars \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m<\u001b[39m max_chars):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotValidLength(text, min_chars, max_chars)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mNotValidLength\u001b[0m: There should be a Benaras Pandits (Yogi owner) for UP and MP‚ô•Ô∏èüåπ(even Ayodhya  Bhakts (Owner PM Modi)<br><br>How would a UP MP IPL team called Benaras Pandits and Ayodhya Bhakts describe itself<br>Describing a hypothetical UP MP IPL team called Benaras Pandits and Ayodhya Bhakts requires careful consideration of cultural sensitivities and responsible representation. Here are some ways they could potentially describe themselves, taking into account inclusivity and respect:<br><br>Emphasizing Heritage and Devotion:<br><br>&quot;Rooted in faith, fueled by fervor: Benaras Pandits and Ayodhya Bhakts, where ancient wisdom meets cricketing grit.&quot;<br><br>&quot;Carrying the legacy of the Ganges and the spirit of Ayodhya: Benaras Pandits and Ayodhya Bhakts, playing with devotion, winning with grace.&quot;<br><br>&quot;From the temples of knowledge to the stadiums of glory: Benaras Pandits and Ayodhya Bhakts, batting for unity, bowling for hope.&quot;<br><br>Celebrating Regional Identity:<br><br>&quot;Awadh&#39;s flair, Banaras&#39; chant: Benaras Pandits and Ayodhya Bhakts, where culture meets cricket, passion takes flight.&quot;<br><br>&quot;Taste the saffron sweets, hear the raspy cheers: Benaras Pandits and Ayodhya Bhakts, bringing UP&#39;s spirit to every boundary, every roar.&quot;<br><br>&quot;From Ganga ghats to Chowk&#39;s maze, this team reflects UP&#39;s soul: Benaras Pandits and Ayodhya Bhakts, celebrating diversity, chasing victory as one.&quot;<br><br>Focusing on Sportsmanship and Unity:<br><br>&quot;Beyond faith, beyond borders: Benaras Pandits and Ayodhya Bhakts, united by the love of the game, driven by the spirit of sportsmanship.&quot;<br><br>&quot;Building bridges, not boundaries: Benaras Pandits and Ayodhya Bhakts, where every six unites, every wicket inspires.&quot;<br><br>&quot;More than just a team, a movement: Benaras Pandits and Ayodhya Bhakts, playing for UP&#39;s pride, winning for India&#39;s glory.&quot;<br><br>It&#39;s important to avoid:<br><br>Exclusivity or discriminatory language: The team description should represent the diversity of Uttar Pradesh and be inclusive of all communities.<br><br>Religious or historical references that could be sensitive or controversial: Focus on broader themes of faith, heritage, and regional identity without specific religious or historical allusions.<br><br>Clich√©s or stereotypes: Use vivid language and imagery to evoke the essence of UP and its cultural richness without relying on overused descriptions.<br><br>By emphasizing inclusivity, cultural pride, and the spirit of sportsmanship, the Benaras Pandits and Ayodhya Bhakts can create a compelling team identity that resonates with fans across Uttar Pradesh and beyond.<br><br>Remember, responsible representation and sensitivity are crucial when creating narratives around cultural identities. This approach can ensure the team fosters a sense of unity and celebrates the diverse tapestry of Uttar Pradesh without perpetuating stereotypes or causing offense.<br><br>How are the names a postmodern juxtaposition with other modern team names in IPL<br>The names &quot;Benaras Pandits&quot; and &quot;Ayodhya Bhakts&quot; for a hypothetical UP MP IPL team offer an interesting postmodern juxtaposition with other modern team names in the IPL. Here&#39;s how:<br><br>Postmodern Elements:<br><br>Challenge to Grand Narratives: Both names, particularly &quot;Ayodhya Bhakts,&quot; evoke specific religious and cultural associations. This can be seen as a challenge to the IPL&#39;s broader, global appeal, which seeks to transcend regional and religious affiliations.<br><br>Irony and Self-Awareness: The names employ terms typically associated with traditional identities (&quot;Pandits,&quot; &quot;Bhakts&quot;). This self-awareness, bordering on irony, could be interpreted as a playful subversion of expectations, questioning the rigidity of these identities in a modern sporting context.<br><br>Emphasis on Local Context: Unlike most IPL team names, which tend to be generic or aspirational, these names are deeply rooted in the specific geographic and cultural context of Uttar Pradesh. This local focus highlights the diversity and uniqueness of the region within the larger IPL landscape.<br><br>Juxtaposition with Modern IPL Team Names:<br><br>Majority Focus on City/Franchise: Most IPL team names are built around the city or franchise name, aiming for a neutral and commercially appealing brand. For example, Mumbai Indians, Chennai Super Kings, etc.<br><br>Universal Aspirations: Modern IPL team names often use powerful words or concepts like &quot;Kings,&quot; &quot;Royals,&quot; &quot;Daredevils,&quot; or &quot;Riders,&quot; aiming to convey strength, ambition, and excitement.<br><br>Global Appeal: The IPL strives to be a global sporting event, with team names aiming to resonate with a diverse international audience. This is why most names avoid specific cultural or religious references.<br><br>Potential Reactions:<br><br>Pride and Connection: For fans from Uttar Pradesh, these names could spark a sense of pride and connection to their region&#39;s unique identity. They might resonate with the team&#39;s cultural and religious connotations.<br><br>Discomfort and Disconnection: For fans from other regions or cultural backgrounds, the names might evoke discomfort or a sense of alienation. The religious and historical associations could create barriers to identification with the team.<br><br>Intrigue and Discussion: The unconventional nature of the names might pique interest and lead to discussions about representation, branding, and the IPL&#39;s role in Indian society.<br><br>Ultimately, the effectiveness of these names as a postmodern juxtaposition hinges on their execution and reception. Careful consideration of cultural sensitivities, inclusivity, and the desired brand image is crucial. These names offer a unique opportunity to challenge norms and spark conversations, but they also carry the potential for divisiveness and misunderstanding.<br><br>It&#39;s worth noting that while exploring postmodern elements can be exciting, it&#39;s important to maintain respect and sensitivity towards diverse cultural and religious viewpoints. The goal should be to create a brand identity that is both unique and inclusive, celebrating the spirit of cricket and the tapestry of India&#39;s diverse population.<br><br>I hope this analysis provides a comprehensive understanding of the names&#39; potential impact and the creative possibilities they offer within the context of the IPL. Feel free to explore this further and share your own thoughts and interpretations!<br><br><br><br><br><br><br>Bardüåπüåπ‚ô•Ô∏è‚ô•Ô∏è --> Text length need to be between 0 and 5000 characters"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import pandas as pd\n",
    "\n",
    "# Function to translate a batch of texts\n",
    "def translate_batch(texts, source_lang='hi', target_lang='en'):\n",
    "    translations = GoogleTranslator(source=source_lang, target=target_lang).translate_batch(texts)\n",
    "    return translations\n",
    "\n",
    "# Define the file path for the original comments CSV file\n",
    "csv_file_path = 'comments.csv'\n",
    "\n",
    "# Read the original comments CSV file into a DataFrame\n",
    "comments_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Define the batch size for translation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the number of batches\n",
    "num_batches = (len(comments_df) - 1) // batch_size + 1\n",
    "\n",
    "# Initialize an empty list to store translated texts\n",
    "translated_texts = []\n",
    "\n",
    "# Iterate over batches\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(comments_df))\n",
    "    \n",
    "    # Extract batch of comments\n",
    "    batch_comments = comments_df.iloc[start_idx:end_idx]['text'].tolist()\n",
    "    \n",
    "    # Translate the batch of comments\n",
    "    batch_translations = translate_batch(batch_comments)\n",
    "    \n",
    "    # Append translations to the list\n",
    "    translated_texts.extend(batch_translations)\n",
    "    \n",
    "    # Inform about the completion of the batch translation\n",
    "    print(f\"Batch {i+1}/{num_batches} translated.\")\n",
    "\n",
    "# Add the translated texts to the original DataFrame as a new column\n",
    "comments_df['english_texts'] = translated_texts\n",
    "\n",
    "# Save the DataFrame with translations to the same CSV file\n",
    "comments_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(\"Translated texts have been added to the original CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dea496",
   "metadata": {},
   "source": [
    "# New Translated Dataset received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3202bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated comments have been saved to translated_comments.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming translated_texts is your list of translated texts\n",
    "# Assuming comments_df is your DataFrame containing the original comments\n",
    "\n",
    "# Slice the DataFrame to include only the first 8000 rows\n",
    "comments_df_subset = comments_df.head(8000)\n",
    "\n",
    "# Create a DataFrame with the translated comments and authors\n",
    "translated_df = pd.DataFrame({\n",
    "    'author': comments_df_subset['author'],\n",
    "    'english_texts': translated_texts[:8000]  # Slice the translated_texts list to match the number of comments\n",
    "})\n",
    "\n",
    "# Define the file path where you want to save the CSV file\n",
    "csv_file_path = 'translated_comments.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "translated_df.to_csv(csv_file_path, index=True)\n",
    "\n",
    "print(f\"Translated comments have been saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "004b762b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>english_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@SumitGupta-it6ic</td>\n",
       "      <td>Brother, the most dangerous pacer of this seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@Mrhameedraza</td>\n",
       "      <td>All the teams will reach your mother.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@Mrhameedraza</td>\n",
       "      <td>There is weakness in the whole team so that yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@ShiaLovERs572</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@ShiaLovERs572</td>\n",
       "      <td>KKR üíúüòà Final Winners üíú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7995</td>\n",
       "      <td>@urmilajangir927</td>\n",
       "      <td>CSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7996</td>\n",
       "      <td>@SultanRezan</td>\n",
       "      <td>4th place BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7997</td>\n",
       "      <td>@AliElif-gp8fo</td>\n",
       "      <td>&amp;quot;Arre friend! Have you heard about 4RABeT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7998</td>\n",
       "      <td>@DemetFatih</td>\n",
       "      <td>Every IPL game, dreaming of that BMW X3 raffle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>7999</td>\n",
       "      <td>@ZaferMuhlis</td>\n",
       "      <td>‚Çπ10 lakhs cash prize by 4RABeT, just picturing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0             author  \\\n",
       "0              0  @SumitGupta-it6ic   \n",
       "1              1      @Mrhameedraza   \n",
       "2              2      @Mrhameedraza   \n",
       "3              3     @ShiaLovERs572   \n",
       "4              4     @ShiaLovERs572   \n",
       "...          ...                ...   \n",
       "7995        7995   @urmilajangir927   \n",
       "7996        7996       @SultanRezan   \n",
       "7997        7997     @AliElif-gp8fo   \n",
       "7998        7998        @DemetFatih   \n",
       "7999        7999       @ZaferMuhlis   \n",
       "\n",
       "                                          english_texts  \n",
       "0     Brother, the most dangerous pacer of this seas...  \n",
       "1                 All the teams will reach your mother.  \n",
       "2     There is weakness in the whole team so that yo...  \n",
       "3                                                   NaN  \n",
       "4                                KKR üíúüòà Final Winners üíú  \n",
       "...                                                 ...  \n",
       "7995                                                CSK  \n",
       "7996                                      4th place BMW  \n",
       "7997  &quot;Arre friend! Have you heard about 4RABeT...  \n",
       "7998  Every IPL game, dreaming of that BMW X3 raffle...  \n",
       "7999  ‚Çπ10 lakhs cash prize by 4RABeT, just picturing...  \n",
       "\n",
       "[8000 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the translated comments CSV file into a DataFrame with a specified encoding\n",
    "data = pd.read_csv(csv_file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44dba8",
   "metadata": {},
   "source": [
    "# Replace all the emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf58e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5503e0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0             author  \\\n",
      "0              0  @SumitGupta-it6ic   \n",
      "1              1      @Mrhameedraza   \n",
      "2              2      @Mrhameedraza   \n",
      "3              3     @ShiaLovERs572   \n",
      "4              4     @ShiaLovERs572   \n",
      "...          ...                ...   \n",
      "7995        7995   @urmilajangir927   \n",
      "7996        7996       @SultanRezan   \n",
      "7997        7997     @AliElif-gp8fo   \n",
      "7998        7998        @DemetFatih   \n",
      "7999        7999       @ZaferMuhlis   \n",
      "\n",
      "                                          english_texts  \\\n",
      "0     Brother, the most dangerous pacer of this seas...   \n",
      "1                 All the teams will reach your mother.   \n",
      "2     There is weakness in the whole team so that yo...   \n",
      "3                                                   NaN   \n",
      "4                                KKR üíúüòà Final Winners üíú   \n",
      "...                                                 ...   \n",
      "7995                                                CSK   \n",
      "7996                                      4th place BMW   \n",
      "7997  &quot;Arre friend! Have you heard about 4RABeT...   \n",
      "7998  Every IPL game, dreaming of that BMW X3 raffle...   \n",
      "7999  ‚Çπ10 lakhs cash prize by 4RABeT, just picturing...   \n",
      "\n",
      "                                          replaced_text sentiment  \n",
      "0     Brother, the most dangerous pacer of this seas...  negative  \n",
      "1                 All the teams will reach your mother.   neutral  \n",
      "2     There is weakness in the whole team so that yo...  positive  \n",
      "3                                                   NaN       NaN  \n",
      "4                 KKR  good  good  Final Winners  good   positive  \n",
      "...                                                 ...       ...  \n",
      "7995                                                CSK   neutral  \n",
      "7996                                      4th place BMW   neutral  \n",
      "7997  &quot;Arre friend! Have you heard about 4RABeT...  positive  \n",
      "7998  Every IPL game, dreaming of that BMW X3 raffle...  positive  \n",
      "7999  ‚Çπ10 lakhs cash prize by 4RABeT, just picturing...  positive  \n",
      "\n",
      "[8000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def classify_emoji(emoji_char):\n",
    "    \"\"\"Classify the sentiment of an emoji.\"\"\"\n",
    "    emoji_description = emoji.demojize(emoji_char)\n",
    "    if 'heart' in emoji_description:\n",
    "        return 'good'  # Treat all heart emojis as positive by default\n",
    "    else:\n",
    "        sentiment_score = TextBlob(emoji_description).sentiment.polarity\n",
    "        if sentiment_score <= -0.05:\n",
    "            return 'bad'\n",
    "        else:\n",
    "            return 'good'\n",
    "\n",
    "def replace_emojis_with_sentiment(text):\n",
    "    \"\"\"Replace all emojis in the text with their sentiment equivalents.\"\"\"\n",
    "    # Convert text to a list of characters\n",
    "    text_list = list(text)\n",
    "    index = 0\n",
    "    while index < len(text_list):\n",
    "        char = text_list[index]\n",
    "        # Check if the character is an emoji\n",
    "        if emoji.is_emoji(char):\n",
    "            # Get the sentiment equivalent of the emoji\n",
    "            sentiment = classify_emoji(char)\n",
    "            # Replace the emoji with its sentiment equivalent\n",
    "            text_list[index] = f' {sentiment} '\n",
    "        index += 1\n",
    "    # Convert the list back to a string\n",
    "    processed_text = ''.join(text_list)\n",
    "    return processed_text\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # Replace emojis with their sentiment equivalents\n",
    "    replaced_text = replace_emojis_with_sentiment(text)\n",
    "    \n",
    "    # Analyze the sentiment of the replaced text\n",
    "    sentiment_score = TextBlob(replaced_text).sentiment.polarity\n",
    "    \n",
    "    # Determine the sentiment label based on the sentiment score\n",
    "    if sentiment_score > 0:\n",
    "        sentiment = 'positive'\n",
    "    elif sentiment_score < 0:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    \n",
    "    return replaced_text, sentiment\n",
    "\n",
    "# Read the translated comments CSV file into a DataFrame\n",
    "csv_file_path = 'translated_comments.csv'\n",
    "data = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "\n",
    "# Apply sentiment analysis and emoji replacement for the first 10000 rows\n",
    "for i, row in data.head(10000).iterrows():  # Adjusted to iterate over the first 10000 rows\n",
    "    if pd.notna(row['english_texts']):\n",
    "        replaced_text, sentiment = analyze_sentiment(row['english_texts'])\n",
    "        dat.at[i, 'replaced_text'] = replaced_text  # Use `dat` instead of `data`\n",
    "        dat.at[i, 'sentiment'] = sentiment  # Use `dat` instead of `data`\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "output_csv_file_path = 'updated_comments.csv'  # Adjusted filename\n",
    "dat.to_csv(output_csv_file_path, index=False)  # Use `dat` instead of `data`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "920e7791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>english_texts</th>\n",
       "      <th>replaced_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@SumitGupta-it6ic</td>\n",
       "      <td>Brother, the most dangerous pacer of this seas...</td>\n",
       "      <td>Brother, the most dangerous pacer of this seas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@Mrhameedraza</td>\n",
       "      <td>All the teams will reach your mother.</td>\n",
       "      <td>All the teams will reach your mother.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@Mrhameedraza</td>\n",
       "      <td>There is weakness in the whole team so that yo...</td>\n",
       "      <td>There is weakness in the whole team so that yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@ShiaLovERs572</td>\n",
       "      <td>KKR üíúüòà Final Winners üíú</td>\n",
       "      <td>KKR  good  good  Final Winners  good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@AshwiniDurgade-ib9im</td>\n",
       "      <td>This time in IPL semi final to GT, CSK MI AND ...</td>\n",
       "      <td>This time in IPL semi final to GT, CSK MI AND ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>7995</td>\n",
       "      <td>@urmilajangir927</td>\n",
       "      <td>CSK</td>\n",
       "      <td>CSK</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7996</td>\n",
       "      <td>@SultanRezan</td>\n",
       "      <td>4th place BMW</td>\n",
       "      <td>4th place BMW</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7997</td>\n",
       "      <td>@AliElif-gp8fo</td>\n",
       "      <td>&amp;quot;Arre friend! Have you heard about 4RABeT...</td>\n",
       "      <td>&amp;quot;Arre friend! Have you heard about 4RABeT...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7998</td>\n",
       "      <td>@DemetFatih</td>\n",
       "      <td>Every IPL game, dreaming of that BMW X3 raffle...</td>\n",
       "      <td>Every IPL game, dreaming of that BMW X3 raffle...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7999</td>\n",
       "      <td>@ZaferMuhlis</td>\n",
       "      <td>‚Çπ10 lakhs cash prize by 4RABeT, just picturing...</td>\n",
       "      <td>‚Çπ10 lakhs cash prize by 4RABeT, just picturing...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7999 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                 author  \\\n",
       "0              0      @SumitGupta-it6ic   \n",
       "1              1          @Mrhameedraza   \n",
       "2              2          @Mrhameedraza   \n",
       "3              4         @ShiaLovERs572   \n",
       "4              5  @AshwiniDurgade-ib9im   \n",
       "...          ...                    ...   \n",
       "7994        7995       @urmilajangir927   \n",
       "7995        7996           @SultanRezan   \n",
       "7996        7997         @AliElif-gp8fo   \n",
       "7997        7998            @DemetFatih   \n",
       "7998        7999           @ZaferMuhlis   \n",
       "\n",
       "                                          english_texts  \\\n",
       "0     Brother, the most dangerous pacer of this seas...   \n",
       "1                 All the teams will reach your mother.   \n",
       "2     There is weakness in the whole team so that yo...   \n",
       "3                                KKR üíúüòà Final Winners üíú   \n",
       "4     This time in IPL semi final to GT, CSK MI AND ...   \n",
       "...                                                 ...   \n",
       "7994                                                CSK   \n",
       "7995                                      4th place BMW   \n",
       "7996  &quot;Arre friend! Have you heard about 4RABeT...   \n",
       "7997  Every IPL game, dreaming of that BMW X3 raffle...   \n",
       "7998  ‚Çπ10 lakhs cash prize by 4RABeT, just picturing...   \n",
       "\n",
       "                                          replaced_text sentiment  \n",
       "0     Brother, the most dangerous pacer of this seas...  negative  \n",
       "1                 All the teams will reach your mother.   neutral  \n",
       "2     There is weakness in the whole team so that yo...  positive  \n",
       "3                 KKR  good  good  Final Winners  good   positive  \n",
       "4     This time in IPL semi final to GT, CSK MI AND ...  positive  \n",
       "...                                                 ...       ...  \n",
       "7994                                                CSK   neutral  \n",
       "7995                                      4th place BMW   neutral  \n",
       "7996  &quot;Arre friend! Have you heard about 4RABeT...  positive  \n",
       "7997  Every IPL game, dreaming of that BMW X3 raffle...  positive  \n",
       "7998  ‚Çπ10 lakhs cash prize by 4RABeT, just picturing...  positive  \n",
       "\n",
       "[7999 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = 'updated_comments.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83014a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
